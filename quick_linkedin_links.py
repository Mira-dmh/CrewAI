"""
å¿«é€ŸLinkedInæœç´¢é“¾æ¥ç”Ÿæˆå™¨
ä¸“æ³¨äºç”Ÿæˆæœ‰æ•ˆçš„LinkedInæœç´¢URLï¼Œä¸æ¶‰åŠæ•°æ®æŠ“å–
é€‚ç”¨äºå¿«é€Ÿç”Ÿæˆæœç´¢é“¾æ¥è¿›è¡Œæ‰‹åŠ¨æµè§ˆ
"""

import pandas as pd
import urllib.parse
from datetime import datetime
import json

def generate_linkedin_job_links(keywords, locations, companies=None):
    """
    ç”ŸæˆLinkedInèŒä½æœç´¢é“¾æ¥
    
    å‚æ•°:
    - keywords: æœç´¢å…³é”®è¯åˆ—è¡¨
    - locations: åœ°ç‚¹åˆ—è¡¨
    - companies: å…¬å¸åç§°åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
    
    è¿”å›: åŒ…å«æ‰€æœ‰æœç´¢ç»„åˆçš„å­—å…¸
    """
    
    search_links = []
    
    for keyword in keywords:
        for location in locations:
            # URLç¼–ç 
            keyword_encoded = urllib.parse.quote(keyword)
            location_encoded = urllib.parse.quote(location)
            
            # åŸºç¡€æœç´¢é“¾æ¥
            base_link = {
                'keyword': keyword,
                'location': location,
                'basic_search': f"https://www.linkedin.com/jobs/search/?keywords={keyword_encoded}&location={location_encoded}",
                'recent_posts': f"https://www.linkedin.com/jobs/search/?keywords={keyword_encoded}&location={location_encoded}&sortBy=DD",
                'easy_apply': f"https://www.linkedin.com/jobs/search/?keywords={keyword_encoded}&location={location_encoded}&f_AL=true",
                'remote_jobs': f"https://www.linkedin.com/jobs/search/?keywords={keyword_encoded}&location={location_encoded}&f_WT=2",
                'full_time': f"https://www.linkedin.com/jobs/search/?keywords={keyword_encoded}&location={location_encoded}&f_JT=F",
                'entry_level': f"https://www.linkedin.com/jobs/search/?keywords={keyword_encoded}&location={location_encoded}&f_E=1",
                'mid_level': f"https://www.linkedin.com/jobs/search/?keywords={keyword_encoded}&location={location_encoded}&f_E=3",
                'senior_level': f"https://www.linkedin.com/jobs/search/?keywords={keyword_encoded}&location={location_encoded}&f_E=4"
            }
            
            # Googleæœç´¢LinkedInçš„é“¾æ¥
            google_searches = {
                'google_basic': f"https://www.google.com/search?q=site:linkedin.com/jobs+{keyword_encoded}+{location_encoded}",
                'google_recent': f"https://www.google.com/search?q=site:linkedin.com/jobs+{keyword_encoded}+{location_encoded}&tbs=qdr:w",
                'google_exact': f"https://www.google.com/search?q=site:linkedin.com/jobs/view+{keyword_encoded}+location:{location_encoded}"
            }
            
            # åˆå¹¶é“¾æ¥
            combined_links = {**base_link, **google_searches}
            
            # å¦‚æœæä¾›äº†å…¬å¸åˆ—è¡¨ï¼Œæ·»åŠ å…¬å¸ç‰¹å®šæœç´¢
            if companies:
                company_links = {}
                for company in companies:
                    company_encoded = urllib.parse.quote(company)
                    company_slug = company.lower().replace(' ', '-').replace('&', 'and')
                    
                    company_links[f'company_{company}'] = {
                        'jobs_page': f"https://www.linkedin.com/company/{company_slug}/jobs/",
                        'jobs_search': f"https://www.linkedin.com/jobs/search/?keywords={keyword_encoded}&location={location_encoded}&f_C={company_encoded}",
                        'google_company': f"https://www.google.com/search?q={company_encoded}+{keyword_encoded}+site:linkedin.com/jobs"
                    }
                
                combined_links['companies'] = company_links
            
            search_links.append(combined_links)
    
    return search_links

def create_quick_access_csv(keywords, locations, companies=None):
    """
    åˆ›å»ºå¿«é€Ÿè®¿é—®çš„CSVæ–‡ä»¶
    """
    
    print("ğŸ”— ç”ŸæˆLinkedInæœç´¢é“¾æ¥...")
    
    all_links = []
    
    for keyword in keywords:
        for location in locations:
            # URLç¼–ç 
            keyword_encoded = urllib.parse.quote(keyword)
            location_encoded = urllib.parse.quote(location)
            
            # åˆ›å»ºåŸºç¡€æœç´¢è®°å½•
            searches = [
                {
                    'search_type': 'åŸºç¡€æœç´¢',
                    'keyword': keyword,
                    'location': location,
                    'description': 'æ ‡å‡†LinkedInèŒä½æœç´¢',
                    'url': f"https://www.linkedin.com/jobs/search/?keywords={keyword_encoded}&location={location_encoded}",
                    'category': 'linkedin_direct'
                },
                {
                    'search_type': 'æœ€æ–°èŒä½',
                    'keyword': keyword,
                    'location': location,
                    'description': 'æŒ‰æ—¶é—´æ’åºçš„æœ€æ–°èŒä½',
                    'url': f"https://www.linkedin.com/jobs/search/?keywords={keyword_encoded}&location={location_encoded}&sortBy=DD",
                    'category': 'linkedin_direct'
                },
                {
                    'search_type': 'å¿«é€Ÿç”³è¯·',
                    'keyword': keyword,
                    'location': location,
                    'description': 'æ”¯æŒä¸€é”®ç”³è¯·çš„èŒä½',
                    'url': f"https://www.linkedin.com/jobs/search/?keywords={keyword_encoded}&location={location_encoded}&f_AL=true",
                    'category': 'linkedin_direct'
                },
                {
                    'search_type': 'è¿œç¨‹å·¥ä½œ',
                    'keyword': keyword,
                    'location': location,
                    'description': 'è¿œç¨‹åŠå…¬èŒä½',
                    'url': f"https://www.linkedin.com/jobs/search/?keywords={keyword_encoded}&location={location_encoded}&f_WT=2",
                    'category': 'linkedin_direct'
                },
                {
                    'search_type': 'Googleæœç´¢LinkedIn',
                    'keyword': keyword,
                    'location': location,
                    'description': 'é€šè¿‡Googleæœç´¢LinkedInèŒä½',
                    'url': f"https://www.google.com/search?q=site:linkedin.com/jobs+{keyword_encoded}+{location_encoded}",
                    'category': 'google_search'
                },
                {
                    'search_type': 'Googleæœ€è¿‘ä¸€å‘¨',
                    'keyword': keyword,
                    'location': location,
                    'description': 'Googleæœç´¢æœ€è¿‘ä¸€å‘¨çš„LinkedInèŒä½',
                    'url': f"https://www.google.com/search?q=site:linkedin.com/jobs+{keyword_encoded}+{location_encoded}&tbs=qdr:w",
                    'category': 'google_search'
                }
            ]
            
            all_links.extend(searches)
            
            # å¦‚æœæä¾›äº†å…¬å¸ï¼Œæ·»åŠ å…¬å¸ç‰¹å®šæœç´¢
            if companies:
                for company in companies:
                    company_slug = company.lower().replace(' ', '-').replace('&', 'and')
                    
                    company_searches = [
                        {
                            'search_type': f'{company} - å…¬å¸èŒä½é¡µ',
                            'keyword': keyword,
                            'location': location,
                            'description': f'{company}å…¬å¸çš„LinkedInèŒä½é¡µé¢',
                            'url': f"https://www.linkedin.com/company/{company_slug}/jobs/",
                            'category': 'company_page'
                        },
                        {
                            'search_type': f'{company} - Googleæœç´¢',
                            'keyword': keyword,
                            'location': location,
                            'description': f'Googleæœç´¢{company}åœ¨LinkedInçš„{keyword}èŒä½',
                            'url': f"https://www.google.com/search?q={urllib.parse.quote(company)}+{keyword_encoded}+site:linkedin.com/jobs",
                            'category': 'company_google'
                        }
                    ]
                    
                    all_links.extend(company_searches)
    
    # æ·»åŠ åˆ›å»ºæ—¶é—´
    for link in all_links:
        link['created_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    
    return all_links

def main():
    """
    ä¸»å‡½æ•° - å¿«é€Ÿç”ŸæˆLinkedInæœç´¢é“¾æ¥
    """
    print("ğŸ”— LinkedInå¿«é€Ÿæœç´¢é“¾æ¥ç”Ÿæˆå™¨")
    print("=" * 50)
    print("ç”Ÿæˆå„ç§LinkedInæœç´¢é“¾æ¥ï¼Œæ— éœ€APIæˆ–æ•°æ®æŠ“å–")
    print()
    
    # ç”¨æˆ·è¾“å…¥
    keywords_input = input("è¯·è¾“å…¥æœç´¢å…³é”®è¯ (ç”¨é€—å·åˆ†éš”): ").strip()
    if not keywords_input:
        keywords = ["data scientist", "python developer", "machine learning engineer"]
        print(f"ä½¿ç”¨é»˜è®¤å…³é”®è¯: {keywords}")
    else:
        keywords = [k.strip() for k in keywords_input.split(',')]
    
    locations_input = input("è¯·è¾“å…¥æœç´¢åœ°ç‚¹ (ç”¨é€—å·åˆ†éš”): ").strip()
    if not locations_input:
        locations = ["United States", "New York", "San Francisco", "Remote"]
        print(f"ä½¿ç”¨é»˜è®¤åœ°ç‚¹: {locations}")
    else:
        locations = [l.strip() for l in locations_input.split(',')]
    
    companies_input = input("è¯·è¾“å…¥ç›®æ ‡å…¬å¸ (ç”¨é€—å·åˆ†éš”, å¯é€‰): ").strip()
    companies = [c.strip() for c in companies_input.split(',')] if companies_input else None
    
    print(f"\nğŸ¯ ç”Ÿæˆé…ç½®:")
    print(f"å…³é”®è¯æ•°é‡: {len(keywords)}")
    print(f"åœ°ç‚¹æ•°é‡: {len(locations)}")
    print(f"ç›®æ ‡å…¬å¸: {len(companies) if companies else 0}")
    
    # ç”Ÿæˆæ‰€æœ‰æœç´¢é“¾æ¥
    search_data = create_quick_access_csv(keywords, locations, companies)
    
    # ä¿å­˜ä¸ºCSV
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    csv_filename = f"linkedin_search_links_{timestamp}.csv"
    
    df = pd.DataFrame(search_data)
    df.to_csv(csv_filename, index=False, encoding='utf-8-sig')
    
    print(f"\nâœ… æœç´¢é“¾æ¥å·²ä¿å­˜åˆ°: {csv_filename}")
    print(f"ğŸ“Š ç”Ÿæˆäº† {len(search_data)} ä¸ªæœç´¢é“¾æ¥")
    
    # æ˜¾ç¤ºç»Ÿè®¡
    category_counts = df['category'].value_counts()
    print(f"\nğŸ“ˆ é“¾æ¥ç±»å‹ç»Ÿè®¡:")
    for category, count in category_counts.items():
        print(f"  {category}: {count} ä¸ªé“¾æ¥")
    
    # æ˜¾ç¤ºå‰10ä¸ªé“¾æ¥ç¤ºä¾‹
    print(f"\nğŸ” å‰10ä¸ªæœç´¢é“¾æ¥:")
    for i, row in df.head(10).iterrows():
        print(f"{i+1:2d}. {row['search_type']} | {row['keyword']} @ {row['location']}")
        print(f"    {row['url'][:80]}...")
    
    # ç”ŸæˆJSONæ ¼å¼ï¼ˆç»“æ„åŒ–æ•°æ®ï¼‰
    json_filename = f"linkedin_searches_structured_{timestamp}.json"
    structured_data = generate_linkedin_job_links(keywords, locations, companies)
    
    with open(json_filename, 'w', encoding='utf-8') as f:
        json.dump(structured_data, f, indent=2, ensure_ascii=False)
    
    print(f"\nâœ… ç»“æ„åŒ–æ•°æ®å·²ä¿å­˜åˆ°: {json_filename}")
    
    print(f"\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
    print(f"1. åœ¨Excelæˆ–Google Sheetsä¸­æ‰“å¼€CSVæ–‡ä»¶")
    print(f"2. ç‚¹å‡»URLåˆ—çš„é“¾æ¥ç›´æ¥è®¿é—®LinkedInæœç´¢")
    print(f"3. æ ¹æ®éœ€è¦ç­›é€‰ä¸åŒçš„æœç´¢ç±»å‹")
    print(f"4. ç»“åˆGoogleæœç´¢è·å¾—æ›´å…¨é¢çš„ç»“æœ")
    
    # æµ‹è¯•å‡ ä¸ªé“¾æ¥çš„å¯è®¿é—®æ€§
    print(f"\nğŸ” æµ‹è¯•é“¾æ¥å¯è®¿é—®æ€§...")
    import requests
    
    test_urls = df.head(3)['url'].tolist()
    
    for i, url in enumerate(test_urls):
        try:
            response = requests.head(url, timeout=5, allow_redirects=True)
            status = "âœ…" if response.status_code in [200, 302] else f"âŒ {response.status_code}"
            print(f"{i+1}. {status} - {url[:60]}...")
        except Exception as e:
            print(f"{i+1}. âŒ ç½‘ç»œé”™è¯¯ - {url[:60]}...")

if __name__ == "__main__":
    main()