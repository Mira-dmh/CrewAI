# LinkedIn Specific Tasks Configuration
# These tasks are specifically designed for LinkedIn job search and market analysis

dashboard_input_processing_task:
  description: >
    Process comprehensive user input from the dashboard to extract all search parameters:
    - Job Title: {job_title} (REQUIRED)
    - Location: {location} (optional - city, state, zip code)
    - Company: {company} (optional - specific company or leave empty for all)
    - Job Type: {job_type} (Full-time, Part-time, Internship, Contract, Temporary, or Any)
    - Work Mode: {remote_option} (Remote, Hybrid, On-site, or Any)
    - Date Posted: {date_posted} (Past 24 hours, Past week, Past month, or Any time)
    - Work Authorization: {work_authorization} (OPT, CPT, US Visa Sponsorship, or Any)
    
    Validate all inputs, set defaults for empty values, and structure the data for the LinkedIn scraper.
    Ensure job_title is always provided. Create an optimized search query that combines all filters.
  expected_output: >
    A structured JSON response with validated and formatted search parameters:
    {
      "request_type": "linkedin_job_search",
      "search_parameters": {
        "job_title": "validated job title (REQUIRED)",
        "location": "validated location or empty string",
        "company": "validated company name or empty string for all companies",
        "job_type": "Full-time/Part-time/Internship/Contract/Temporary or Any",
        "remote_option": "Remote/Hybrid/On-site or Any",
        "date_posted": "Past 24 hours/Past week/Past month or Any time",
        "work_authorization": "OPT/CPT/US Visa Sponsorship or Any"
      },
      "routing_recommendation": "linkedin_scraper",
      "processed_query": "optimized search query combining all filters",
      "validation_status": "valid or invalid",
      "validation_errors": ["list of any validation errors if invalid"]
    }

linkedin_scraping_task:
  description: >
    You are tasked with finding REAL LinkedIn job postings using your tools.
    
    USER INPUT PARAMETERS:
    - Job Title: {job_title} (REQUIRED)
    - Location: {location}
    - Company: {company}
    - Job Type: {job_type}
    - Work Mode: {remote_option}
    - Date Posted: {date_posted}
    - Work Authorization: {work_authorization}
    
    STEP 1: Use the "Search LinkedIn Jobs with Filters" tool
    - Pass all user parameters as JSON to get the search strategy
    
    STEP 2: Use SerperDev tool to search LinkedIn (MULTIPLE SEARCHES)
    - Build a SIMPLE search query: "site:linkedin.com/jobs [job_title] [location]"
    - Do NOT include too many filters in the search query - it makes searches fail
    - Start broad, then filter results programmatically
    - SerperDev will return up to 50 results per search
    - **IMPORTANT**: To get more jobs, perform MULTIPLE searches with variations:
      * Search 1: "site:linkedin.com/jobs [job_title] [location]"
      * Search 2: "site:linkedin.com/jobs [job_title] [broader_location]" (e.g., state instead of zip)
      * Search 3: "site:linkedin.com/jobs [related_job_title] [location]" (e.g., "data analyst" â†’ "business analyst")
    - Combine results from all searches to get 30-50+ unique jobs
    - Example working query: "site:linkedin.com/jobs data analyst Pennsylvania"
    - Example backup query: "site:linkedin.com/jobs data analyst"
    
    STEP 3: Extract job data from SerperDev results
    For EACH result from ALL searches (aim for 30-50+ unique jobs):
    - Extract job_id from LinkedIn URL (numbers after /jobs/view/)
    - **SKIP** results that are collection pages (e.g., "2000+ jobs in...")
    - **ONLY KEEP** results with specific job IDs in the URL
    - Get job_title from the result title
    - Get company_name from the result
    - Get location from the result
    - Infer employment_type from title/description (Full-time, Part-time, Internship, Contract)
    - Infer work_arrangement from description (Remote, Hybrid, On-site)
    - Infer experience_level (Entry level, Mid-Senior level, Executive)
    - Extract salary_range if mentioned in snippet
    - Use result snippet as job_description
    - Extract qualifications if mentioned
    - Build application_url: https://www.linkedin.com/jobs/view/[job_id]
    - Parse date_posted - distinguish "Posted X ago" vs "Reposted X ago"
    - Set is_repost: true if "Reposted" appears, false otherwise
    - Store raw date string in date_info_raw
    - Look for work_authorization keywords (visa, sponsorship, OPT, CPT, H-1B)
    - Extract applicant_count if shown (e.g., "50 applicants")
    - **Remove duplicates** - keep only unique job_ids
    
    STEP 4: Return structured JSON with 30-50+ unique jobs
    - Combine results from all searches
    - Remove duplicates by job_id
    - Sort by most recent date first
    - Target: 30-50 jobs minimum (more is better!)
    
    IMPORTANT:
    - You MUST use SerperDev tool to get real LinkedIn results
    - Do NOT make up job postings
    - Extract information from actual search results
    - If SerperDev returns fewer than 50, that's okay - return what you find
    - Sort results by most recent date first
  expected_output: >
    A complete JSON document with this EXACT structure:
    {
      "search_metadata": {
        "job_title": "{job_title}",
        "location": "{location}",
        "company": "{company}",
        "job_type": "{job_type}",
        "remote_option": "{remote_option}",
        "date_posted": "{date_posted}",
        "work_authorization": "{work_authorization}",
        "search_query": "the actual SerperDev query used",
        "search_date": "ISO format timestamp",
        "total_results_found": "actual number of jobs found"
      },
      "job_postings": [
        {
          "job_id": "extracted from LinkedIn URL",
          "job_title": "exact title from search result",
          "company_name": "company name from result",
          "company_url": "LinkedIn company URL if available",
          "location": "job location from result",
          "employment_type": "Full-time/Part-time/Contract/Internship",
          "work_arrangement": "Remote/Hybrid/On-site",
          "experience_level": "Entry level/Mid-Senior level/Executive",
          "salary_range": "salary if mentioned in result",
          "benefits": "benefits if mentioned",
          "job_description": "snippet from search result",
          "qualifications": "requirements from snippet",
          "application_url": "https://www.linkedin.com/jobs/view/[job_id]",
          "date_posted": "parsed date",
          "repost_date": "parsed repost date if applicable",
          "is_repost": true or false,
          "date_info_raw": "exact date text from result",
          "work_authorization": "visa/sponsorship details if mentioned",
          "applicant_count": "number if shown"
        }
      ]
    }
    
    Return ONLY the JSON, no other text.

linkedin_market_trends_task:
  description: >
    **CRITICAL**: Analyze the ACTUAL LinkedIn job postings data provided by the LinkedIn Scraper agent.
    DO NOT search for external market data - extract ALL insights from the job_postings JSON data.
    
    **DATA SOURCE**: Use the output from linkedin_scraping_task which contains:
    - "search_metadata": job count, search parameters
    - "job_postings": array of job objects with fields like salary_range, location, company_name, 
      job_description, required_skills, experience_level, employment_type, etc.
    
    **ANALYSIS TASKS**:
    1. **Read job descriptions and extract skills**: Parse EVERY job's "job_description" and "required_skills" 
       fields to identify technical skills (Python, SQL, Java, etc.), tools (Tableau, Excel, etc.), 
       and soft skills (communication, teamwork, etc.). Count frequency across ALL jobs.
    
    2. **Parse salary data**: Extract salary information from "salary_range" field for ALL jobs. 
       Calculate minimum, maximum, and average. Handle various formats like "$80K-$100K", 
       "$80,000 - $100,000/year", "80000-100000", etc.
    
    3. **Analyze locations**: Count jobs by "location" field to identify high-demand geographic areas.
    
    4. **Identify top companies**: Count jobs by "company_name" to find top hiring companies.
    
    5. **Experience level distribution**: Count jobs by "experience_level" (Entry, Mid, Senior).
    
    6. **Employment type breakdown**: Count "employment_type" (Full-time, Part-time, Contract, etc.).
    
    7. **Remote work options**: Count "remote_option" (Remote, Hybrid, On-site).
    
    **OUTPUT REQUIREMENTS**:
    - ALL numbers must be REAL counts from the actual data
    - Skills list must include ONLY skills found in job descriptions
    - Salary ranges must be CALCULATED from actual posted salaries
    - Company names must be EXACT names from job postings
    - Use current date (2025-11-11) for analysis_date
    
  expected_output: >
    A comprehensive market analysis report in JSON format with REAL data extracted from job postings:
    {
      "market_overview": {
        "job_title": "extracted from search_metadata",
        "analysis_date": "2025-11-11",
        "total_jobs_analyzed": "EXACT count from job_postings array",
        "market_health": "strong if >30 jobs, moderate if 10-30, weak if <10"
      },
      "salary_data": {
        "average_salary": "CALCULATED average from all salary_range fields",
        "salary_range": {
          "min": "LOWEST salary found in all postings",
          "max": "HIGHEST salary found in all postings"
        },
        "salary_distribution": {
          "under_60k": "count of jobs",
          "60k_to_80k": "count",
          "80k_to_100k": "count",
          "100k_to_150k": "count",
          "over_150k": "count"
        },
        "jobs_with_salary_info": "count of jobs that have salary data",
        "jobs_without_salary": "count of jobs missing salary"
      },
      "in_demand_skills": {
        "top_skills": [
          "LIST of top 15 skills extracted from job descriptions, ordered by frequency"
        ],
        "skill_frequency": {
          "skill_name": "percentage of jobs mentioning this skill (e.g., '65%' if 26 out of 40 jobs)"
        },
        "technical_skills": ["Python", "SQL", "Java", "etc - ONLY if found in descriptions"],
        "tools_and_platforms": ["Tableau", "Excel", "AWS", "etc - ONLY if found"],
        "soft_skills": ["Communication", "Leadership", "etc - ONLY if found"],
        "total_unique_skills_found": "count of distinct skills across all jobs"
      },
      "hiring_patterns": {
        "top_hiring_companies": [
          "EXACT company names from job postings, ordered by job count"
        ],
        "company_job_counts": {
          "Company Name": "number of jobs posted"
        },
        "geographic_distribution": {
          "high_demand_areas": [
            "EXACT locations from job postings, ordered by frequency"
          ],
          "location_job_counts": {
            "City, State": "number of jobs"
          }
        },
        "remote_work_breakdown": {
          "remote": "count of remote jobs",
          "hybrid": "count of hybrid jobs",
          "onsite": "count of onsite jobs",
          "not_specified": "count where remote_option is empty"
        }
      },
      "experience_level_requirements": {
        "entry_level": "percentage (e.g., '20%' if 8 out of 40 jobs)",
        "mid_level": "percentage",
        "senior_level": "percentage",
        "not_specified": "percentage of jobs without experience level",
        "counts": {
          "entry": "actual count",
          "mid": "actual count",
          "senior": "actual count"
        }
      },
      "employment_type_breakdown": {
        "full_time": "percentage and count",
        "part_time": "percentage and count",
        "contract": "percentage and count",
        "internship": "percentage and count"
      },
      "job_posting_trends": {
        "total_postings_found": "EXACT count from job_postings array",
        "posting_freshness": {
          "posted_last_7_days": "count from date_posted field",
          "posted_last_30_days": "count",
          "posted_over_30_days": "count"
        },
        "industries_represented": ["list of unique industries from job postings"],
        "company_sizes": {
          "small_0_50": "count",
          "medium_51_500": "count",
          "large_500_plus": "count"
        }
      },
      "data_completeness": {
        "jobs_with_salary": "percentage",
        "jobs_with_skills": "percentage",
        "jobs_with_description": "percentage",
        "jobs_with_location": "percentage",
        "average_data_quality": "percentage of fields populated"
      }
    }

linkedin_verification_task:
  description: >
    **MISSION**: Verify EACH LinkedIn job posting against trusted ground truth sources and generate 
    quantitative confidence scores using the LinkedIn Job Data Verifier tool.
    
    **GROUND TRUTH SOURCES** (Must reference these):
    1. **U.S. Bureau of Labor Statistics (BLS)** - Official median wages and employment data
    2. **Glassdoor** - Salary ranges, company reviews, and market benchmarks
    3. **Indeed** - Job market trends and salary statistics
    4. **PayScale** - Compensation benchmarks by title and location
    5. **LinkedIn Salary Insights** - Platform's own salary data
    6. **Levels.fyi** - Tech industry salary data (for tech roles)
    
    **VERIFICATION PROCESS**:
    For EACH job posting in the input data:
    
    STEP 1: Use the "LinkedIn Job Data Verifier" tool
    - Pass the job posting data as JSON string
    - Tool will automatically verify against 6 dimensions:
      * Salary Verification (30% weight) - Compare against BLS/Glassdoor/PayScale
      * Company Verification (20% weight) - Validate against LinkedIn/Glassdoor/Fortune lists
      * Job Title Normalization (15% weight) - Check against O*NET taxonomy
      * Location Market Data (15% weight) - Verify against BLS regional data
      * Temporal Consistency (10% weight) - Flag outdated postings (>3 months)
      * Link Validity (10% weight) - Verify LinkedIn URL formats
    
    STEP 2: Collect verification report for each job
    - overall_confidence_score (0-1 scale)
    - confidence_level (HIGH/MEDIUM/LOW)
    - component_scores (breakdown by dimension)
    - flagged_issues (anomalies and warnings)
    - recommendations (actionable next steps)
    
    STEP 3: Aggregate results
    - Calculate average confidence score across all jobs
    - Count jobs by confidence level (HIGH/MEDIUM/LOW)
    - Identify most common issues
    - Flag critical issues requiring immediate attention
    
    **DATE VALIDATION** (Critical):
    - "Reposted X ago" = job was RE-POSTED, not originally posted
    - "Posted X ago" = original posting time
    - Flag jobs older than 3 months as potentially filled
    - Flag jobs older than 1 year as invalid
    
    **OUTPUT REQUIREMENTS**:
    Return comprehensive verification report with trust scores for ALL jobs.
  expected_output: >
    A complete JSON verification report with quantitative confidence scores:
    {
      "verification_summary": {
        "total_jobs_verified": "number of jobs processed",
        "average_confidence_score": "mean score (0-1)",
        "high_confidence_jobs": "count with score >= 0.85",
        "medium_confidence_jobs": "count with score 0.70-0.84",
        "low_confidence_jobs": "count with score < 0.70",
        "flagged_for_review": "count requiring manual review"
      },
      "ground_truth_sources_used": [
        "U.S. Bureau of Labor Statistics (BLS)",
        "Glassdoor Salary Data",
        "Indeed Market Trends",
        "PayScale Benchmarks",
        "LinkedIn Salary Insights",
        "O*NET Occupation Taxonomy"
      ],
      "verified_jobs": [
        {
          "job_id": "LinkedIn job ID",
          "job_title": "job title",
          "company_name": "company name",
          "verification_status": "verified or flagged",
          "overall_confidence_score": "0.xxx (0-1 scale)",
          "confidence_level": "HIGH/MEDIUM/LOW",
          "component_scores": {
            "salary_verification": "0.xxx (30% weight)",
            "company_verification": "0.xxx (20% weight)",
            "title_normalization": "0.xxx (15% weight)",
            "location_market": "0.xxx (15% weight)",
            "temporal_consistency": "0.xxx (10% weight)",
            "link_validity": "0.xxx (10% weight)"
          },
          "flagged_issues": [
            {
              "type": "salary_anomaly or missing_company or outdated_posting etc.",
              "field": "affected field name",
              "severity": "critical/high/medium/low",
              "message": "detailed description of the issue",
              "expected_value": "what the value should be based on ground truth"
            }
          ],
          "recommendations": [
            "actionable recommendations based on verification results"
          ]
        }
      ],
      "critical_issues": [
        {
          "job_id": "job with critical issue",
          "issue_type": "type of critical issue",
          "description": "what needs immediate attention"
        }
      ],
      "date_validation_report": {
        "recent_postings": "count posted within 7 days",
        "moderately_recent": "count posted 8-30 days ago",
        "older_postings": "count posted 1-3 months ago",
        "outdated_postings": "count posted >3 months ago (flagged)",
        "invalid_postings": "count posted >1 year ago (flagged as invalid)"
      },
      "overall_data_quality": "HIGH/MEDIUM/LOW based on average confidence",
      "user_recommendations": [
        "overall recommendations for the user based on verification results"
      ]
    }
    
    Return ONLY the JSON, no other text.
